{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Hand-Written Digit Recognition\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. (Wikipedia) \n",
    "\n",
    "\n",
    "After completing this tutorial you will be able to implement and train a neural network with two hidden layers, that can recognize digit of an image with accuracy more than 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Helper Functions\n",
    "First we need to import the libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # numpy is a standard library for numerical \n",
    "                                       # computations\n",
    "np.random.seed(0)\n",
    "    \n",
    "import tensorflow as tf                # deep learning library, in this tutorial \n",
    "                                       # we will use it only to download the data\n",
    "import matplotlib.pyplot as plt        # matplotlib.pyplot is a plotting library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we need to load the data. It consist of the images and labels. Each image is 28 by 28 pixels and is stored as a flattened `np.array` of length 784 (28 * 28). Each label is a single number from 0 to 9. The data is split into train and test set, which are used for training and evaluating the network respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0cbf978cbc0d>:2: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\WinPython\\python-3.7.0b3.amd64\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# This might throw some warnings \n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images \n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images \n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look how one image (and it's corresponding label) might look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for this image is  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label for this image is \", train_labels[0])\n",
    "plt.imshow(-train_data[0].reshape((28,28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following two helper functions and their derivatives. For further detail please refer to: \n",
    "\n",
    "- https://en.wikipedia.org/wiki/Sigmoid_function\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Softmax_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z, derivative = False): \n",
    "    \"\"\" Sigmoid function (resp. its derivative) of z\n",
    "    \n",
    "    Args: \n",
    "    z -- A np.array (k x 1)\n",
    "    \n",
    "    Returns: \n",
    "    #TODO\n",
    "    \"\"\"\n",
    "    sig = 1/(1+np.exp(-z))\n",
    "    if not derivative:\n",
    "        return sig\n",
    "    else: \n",
    "        return np.diag((sig * (1-sig)).T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z, derivative = False): \n",
    "    \"\"\" Softmax function (resp. its derivative) of z\n",
    "    \n",
    "    Args: \n",
    "    z -- A np.array (k x 1)\n",
    "    \n",
    "    Returns: \n",
    "    # TODO\n",
    "    \"\"\"\n",
    "    e = np.exp(z)\n",
    "    e = e / np.sum(e, axis = 0)\n",
    "    if not derivative:\n",
    "        return e\n",
    "    else:\n",
    "        D_shape = (len(e),)*2\n",
    "        D = np.zeros(D_shape)\n",
    "        for i in range(len(e)): \n",
    "            for j in range(len(e)):\n",
    "                D[i,j] = e[i]*((i==j)*1-e[j])\n",
    "        return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Architecture of the NN\n",
    "\n",
    "Now we define the architecture of the neural network. In our case the network will have \n",
    "- one input layer with 784 (28 * 28) neurons. Each neuron will represent one pixel of the input image. \n",
    "- Two hidden layers with 64 and 32 neurons and a sigmoid activation function. \n",
    "- An output layer with 10 neurons and softmax activation function. The `i`-th element of the output vector will correspond to the probability that the input image contains digit `i`. \n",
    "\n",
    "This is a fancy way of saying what can be summarized by this equation: \n",
    "\n",
    "$$ \\hat{y} = softmax\\bigg ( W_{2} \\sigma \\big ( W_{1} \\sigma ( W_{0} x + b_{0}) + b_{1} \\big ) + b_{2} \\bigg ) $$\n",
    "\n",
    "where \n",
    "- $\\hat{y}$ is a (10 x 1) vector of output probabilities \n",
    "- $x$ is a (784 x 1) vector representing pixel values of the input image\n",
    "\n",
    "\n",
    "- $softmax$ is the softmax function \n",
    "- $\\sigma$ is the sigmoid function\n",
    "\n",
    "\n",
    "- $W_{2}$ is a (10 x 32) matrix, $b_{2}$ is a (10 x 1) vector\n",
    "- $W_{1}$ is a (32 x 64) matrix, $b_{1}$ is a (32 x 1) vector\n",
    "- $W_{0}$ is a (64 x 784) matrix, $b_{0}$ is a (784 x 1) vector\n",
    "\n",
    "Note that each layer has the general form of \n",
    "$$l(z) = f(Wz + b) $$\n",
    "and the whole neural network consists of just a few layers stacked over each other. The function $f$ is called an activation function, the input vector $z$ (which is often output of the previous layer or the input to the whole nn) is called an input of the layer and the value $f(Wz + b)$ is called the output of the layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_in_size = 28 ** 2\n",
    "layer_1_size = 64\n",
    "layer_2_size = 32\n",
    "layer_out_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not yet know what values should the matrices and vectors $W_{i}, b_{i}, i = 0, \\dots, 2$ have, so for now, we initialize them randomly. It is important not to pick the random numbers either too large or too small. Do not worry about this now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_0 = np.random.randn(layer_1_size, layer_in_size) / np.sqrt(layer_in_size) ## the np.sqrt() term is there \n",
    "b_0 = np.random.randn(layer_1_size, 1)                                      ## so that each entry of the output \n",
    "                                                                            ## vector has variance +/- 1 \n",
    "W_1 = np.random.randn(layer_2_size, layer_1_size) / np.sqrt(layer_1_size)\n",
    "b_1 = np.random.randn(layer_2_size, 1)\n",
    "\n",
    "W_2 = np.random.randn(layer_out_size, layer_2_size) / np.sqrt(layer_2_size)\n",
    "b_2 = np.random.randn(layer_out_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we write in python the function (our neural network), that calculates the output probabilities from input image $x$ and $W$'s and $b$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, W_0, W_1, W_2, b_0, b_1, b_2): \n",
    "    \"\"\"\n",
    "    Forward pass of the neural network \n",
    "    \n",
    "    Args: \n",
    "    x -- A `np.array` of shape (784,1), \n",
    "        represents the input image. \n",
    "    W_0, W_1, W_2, b_0, b_1, b_2 -- A `np.arrays` \n",
    "        of shapes \n",
    "        (64, 784), \n",
    "        (32, 64), \n",
    "        (10, 32), \n",
    "        (64, 1), \n",
    "        (32, 1), \n",
    "        (10, 1) respectively. \n",
    "        These represent the trainable \n",
    "        parameters of the neural network.\n",
    "        \n",
    "    Returns:\n",
    "    a_2, z_2, a_1, z_1, a_0, z_0 -- A `np.arrays` \n",
    "        of shapes \n",
    "        # TODO\n",
    "        These represent the outputs (#TODO -- terminology for z)\n",
    "        /activations of the nn's layers. \n",
    "    \"\"\"\n",
    "    z_0 = W_0 @ x + b_0\n",
    "    a_0 = sigmoid(z_0)\n",
    "    \n",
    "    z_1 = W_1 @ a_0 + b_1\n",
    "    a_1 = sigmoid(z_1)\n",
    "    \n",
    "    z_2 = W_2 @ a_1 + b_2\n",
    "    a_2 = softmax(z_2)\n",
    "    \n",
    "    return a_2, z_2, a_1, z_1, a_0, z_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our neural network we need to evaluate how well it actually recognizes the images. For the purpose of this, we could use for example the percentage of correctly identified images from the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(W_0, W_1, W_2, b_0, b_1, b_2, eval_data, eval_labels): \n",
    "    \"\"\" Calculates the percentage of correctly identified images on eval_data, eval_labels\n",
    "    \"\"\"\n",
    "    predicted_digits = np.argmax(W_2 @ sigmoid(W_1 @ sigmoid(W_0 @ eval_data.T + b_0) + b_1) + b_2, axis = 0)\n",
    "    acc = np.mean(predicted_digits == eval_labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set is  9.8 %\n"
     ]
    }
   ],
   "source": [
    "acc = calculate_accuracy(W_0, W_1, W_2, b_0, b_1, b_2, eval_data, eval_labels)\n",
    "print(\"Accuracy on the test set is \", acc * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the network has about 10% accuracy on the test set. This is as good as random guess, which is no wonder since we initilized the parameters $W, b$ randomly. \n",
    "\n",
    "Luckily, we can do something about that. First let's ditch the accuracy function we defined above and use another function called cross entropy. Having a prediction $\\hat{y}$ and true label $y$ the cross entropy is defined as $$- y * \\log{\\hat{y}}$$ where $y$ is a vector with 9 zeros and 1 one, which location corresponds to the label digit.  \n",
    "\n",
    "The reason for this change is that the cross entropy is much more precise measure of how good the nn predicts the outputs. Be careful that SMALLER cross entropy means bette predictions. # TODO - explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_hat, y): \n",
    "    \"\"\" Cross Entropy \n",
    "    Args: \n",
    "    y -- A `np.array` of shape (10, 1) with 9 zeros \n",
    "        and 1 one. Represents the true label.  \n",
    "    y_hat -- A `np.array` of shape (10, 1) containing \n",
    "        probabilities, sums up to one. \n",
    "        \n",
    "    Returns: \n",
    "    cross_entropy -- # TODO\n",
    "    \"\"\"\n",
    "    cross_entropy = -np.sum(y * np.log(y_hat), axis=0)\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function (the cross entropy) that measures how good (resp. bad) is a particular choice of $W, b$ in recognizing the digits on images, we can fiddle with the values of $W, b$ and try to maximize (resp. minimize) this function (which is btw. called the loss function in the case of minimization) to achieve the best results in this task. \n",
    "\n",
    "To sumarize, we will now try to minimize \n",
    "\n",
    " $J(x, y, W_0, W_1, W_2, b_0, b_1, b_2) = - y * \\log \\bigg \\lbrace softmax\\bigg ( W_{2} \\sigma \\big ( W_{1} \\sigma ( W_{0} x + b_{0}) + b_{1} \\big ) + b_{2} \\bigg ) \\bigg \\rbrace $\n",
    " \n",
    "with respect to $W_0, W_1, W_2, b_0, b_1, b_2$ across all observations $x, y$, where x = input image, y = output label. To do this we we will use a method called stochastic gradient descent. For this, we will need to calculate gradients of $J$ with respect to $W$'s and $b$'s. \n",
    "\n",
    "\n",
    "This is definitely the hardest part and probably a good time to refresh some matrix calculus. \n",
    "\n",
    "One non-standard rule useful for derivation of the gradients is: \n",
    "$$ \\frac{\\partial}{\\partial W} y^{\\top} f (W z) = (y^{\\top} \\nabla f(W z))^{\\top} z^{\\top} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(x, y, \\\n",
    "                  a_2, z_2, a_1, z_1, a_0, z_0, \\\n",
    "                  W_0, W_1, W_2, b_0, b_1, b_2):\n",
    "    \"\"\"\n",
    "    Calculates gradients of J w.r.t. W_0, W_1, W_2, b_0, b_1, b_2\n",
    "    \n",
    "    Args: \n",
    "    x -- A `np.array` of shape (784,1), \n",
    "        represents the input image. \n",
    "    y -- A `np.array` of shape (10, 1) with 9 zeros \n",
    "        and 1 one. Represents the true label. \n",
    "    a_2, z_2, a_1, z_1, a_0, z_0 -- A `np.array`s \n",
    "        the output of forward pass. \n",
    "    W_0, W_1, W_2, b_0, b_1, b_2 -- A `np.array`s \n",
    "        the parameters of the nn. \n",
    "        \n",
    "    Returns: \n",
    "    dW_0, dW_1, dW_2, db_0.T, db_1.T, db_2.T -- A `np.array`s, \n",
    "        the gradients of J w.r.t. Ws and bs\n",
    "    \"\"\"\n",
    "    db_2 = - y.T @ np.diag(1/a_2.T[0]) @ softmax(z_2, derivative=True)\n",
    "    dW_2 = db_2.T @ a_1.T\n",
    "    \n",
    "    db_1 = db_2 @ W_2 @ sigmoid(z_1, derivative=True) \n",
    "    dW_1 = db_1.T @ a_0.T\n",
    "    \n",
    "    db_0 = db_1 @ W_1 @ sigmoid(z_0, derivative=True)\n",
    "    dW_0 = db_0.T @ x.T\n",
    "    \n",
    "    return dW_0, dW_1, dW_2, db_0.T, db_1.T, db_2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can train the network. At each step we do \n",
    "- the forward pass and calculate the activations \n",
    "- we use the activations to calculate the gradients \n",
    "- we update the parameters of the nn using the obtained gradients \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in iteration  0 is 0.098\n",
      "Accuracy in iteration  100 is 0.6595\n",
      "Accuracy in iteration  200 is 0.8317\n",
      "Accuracy in iteration  300 is 0.8388\n",
      "Accuracy in iteration  400 is 0.8964\n",
      "Accuracy in iteration  500 is 0.9004\n",
      "Accuracy in iteration  600 is 0.9073\n",
      "Accuracy in iteration  700 is 0.915\n",
      "Accuracy in iteration  800 is 0.9178\n",
      "Accuracy in iteration  900 is 0.9188\n"
     ]
    }
   ],
   "source": [
    "train_steps = 1000      # How many times to repeat the gradient descent \n",
    "batch_size = 32         # How many x-y observations to use for the gradient calculation in one step \n",
    "learning_rate = 1.0     # How much to update the parameters using the calculated gradients \n",
    "\n",
    "for i in range(train_steps): \n",
    "    # Check out the original accuracy from time to time\n",
    "    accuracy = calculate_accuracy(W_0, W_1, W_2, b_0, b_1, b_2, eval_data, eval_labels)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Accuracy in iteration \", i, \"is\", accuracy)\n",
    "    \n",
    "    # Select the x,y observations for the gradient calculation\n",
    "    batch_indices = np.random.choice(train_data.shape[0], batch_size)\n",
    "    x_batch = train_data[batch_indices]\n",
    "    y_batch = np.zeros((batch_size, layer_out_size)) \n",
    "    y_batch[range(batch_size), train_labels[batch_indices]] = 1\n",
    "\n",
    "    # Initilize the gradients \n",
    "    grad = [np.zeros_like(t) for t in [W_0, W_1, W_2, b_0, b_1, b_2]]\n",
    "\n",
    "    # Calculate the gradient for each (x,y) pair separately and add to the \n",
    "    # total gradient \n",
    "    for j in range(batch_size): \n",
    "        x = x_batch[j].reshape(-1,1)\n",
    "        y = y_batch[j].reshape(-1,1)\n",
    "        a_2, z_2, a_1, z_1, a_0, z_0 = forward_pass(x, W_0, W_1, W_2, b_0, b_1, b_2)\n",
    "        dt = backward_pass(x, y, \\\n",
    "                      a_2, z_2, a_1, z_1, a_0, z_0, \\\n",
    "                      W_0, W_1, W_2, b_0, b_1, b_2)\n",
    "        grad = [g + g_inc for g,g_inc in zip(grad, dt)]\n",
    "\n",
    "    # Divide the sum of gradients by the number of observations \n",
    "    grad = [g / batch_size for g in grad]\n",
    "    dW_0, dW_1, dW_2, db_0, db_1, db_2 = grad\n",
    "\n",
    "    # Update the parameters \n",
    "    W_0 = W_0 - learning_rate * dW_0\n",
    "    W_1 = W_1 - learning_rate * dW_1\n",
    "    W_2 = W_2 - learning_rate * dW_2\n",
    "    b_0 = b_0 - learning_rate * db_0\n",
    "    b_1 = b_1 - learning_rate * db_1\n",
    "    b_2 = b_2 - learning_rate * db_2\n",
    "    \n",
    "print(\"Training done. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the network does on some evaluation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted number is:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADhhJREFUeJzt3XGMFGWax/HfA4IaIUbDyBIXbzgEoiHKXBq4ZC4XzUZkzzXAHyhEN1xClv1jDbe6xkOiQY2XmIssZ6KuYXWymOwKa1gVFXWJuehtPDcOaBaQO1EzwhwTaCIGiCgRnvtjis2I028P3dVdPfN8Pwnp7nqqup60/qa6+62u19xdAOIZVXQDAIpB+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBHVeM3c2YcIEb29vb+YugVB6enp0+PBhG8q6dYXfzOZLekzSaElPu/sjqfXb29vV3d1dzy4BJJRKpSGvW/PbfjMbLekJST+UdLWkpWZ2da3PB6C56vnMP0fSx+7+qbuflLRR0oJ82gLQaPWE/3JJ+wc87s2WfYuZrTCzbjPrLpfLdewOQJ7qCf9gXyp85/fB7r7e3UvuXmpra6tjdwDyVE/4eyVNHvD4+5IO1NcOgGapJ/zvSZpmZlPMbKykJZK25NMWgEareajP3b8xszskvaH+ob4ud9+dW2cAGqqucX533yppa069AGgiTu8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqLpm6TWzHknHJJ2S9I27l/JoCiPHtm3bKtY2b96c3Pb5559P1o8cOVJTT5Lk7sm6mSXro0alj5vvvvtusl4qFR+VusKfud7dD+fwPACaiLf9QFD1ht8l/dHMtpvZijwaAtAc9b7t73T3A2Z2maRtZvY/7v72wBWyPworJOmKK66oc3cA8lLXkd/dD2S3hyS9IGnOIOusd/eSu5fa2trq2R2AHNUcfjO7yMzGn7kvaZ6kXXk1BqCx6nnbP1HSC9mQyHmSfufur+fSFYCGqzn87v6ppGtz7AUF2LRpU7L+8ssvJ+uvvfZasv7FF19UrFUba586dWqyvnz58mR97ty5FWszZ85Mbrt27dpk/emnn07Wq53D0Arj/Az1AUERfiAowg8ERfiBoAg/EBThB4LK41d9KNg999xTsfb4448nt/3666+T9WrDcdOnT0/W582bV7F25513Jrft6OhI1seMGZOs12POnO+crPote/fuTdYffvjhPNtpCI78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/wjwIYNGyrWvvrqq+S2ixcvTtbvvvvuZP3aa9O/6h47dmyy3qquv/76ZP32229P1kePHp1nOw3BkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcfwTo7OysWHvxxReT2950003J+uzZs2vqabirdtnwkYAjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXWc38y6JP1I0iF3n5ktu1TSJkntknok3eLuRxrXZmwfffRRsv7GG29UrE2ZMiW57aJFi2rqCcPfUI78v5E0/6xlqyS96e7TJL2ZPQYwjFQNv7u/LenzsxYvkHTm8jEbJC3MuS8ADVbrZ/6J7t4nSdntZfm1BKAZGv6Fn5mtMLNuM+sul8uN3h2AIao1/AfNbJIkZbeHKq3o7uvdveTupba2thp3ByBvtYZ/i6Rl2f1lkl7Kpx0AzVI1/Gb2nKT/ljTDzHrNbLmkRyTdYGZ7Jd2QPQYwjFQd53f3pRVKP8i5F1Tw1FNPJesnTpyoWLvxxhuT244fP76mnjD8cYYfEBThB4Ii/EBQhB8IivADQRF+ICgu3T0MpIbyqpk+fXqOnWAk4cgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzj8MvPrqq8n6uHHjKtYWLuTaqhgcR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/hZw/PjxZP3o0aPJ+owZM2p+7l27diXr9bryyisr1i644IKG7htpHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiq4/xm1iXpR5IOufvMbNkDkn4iqZytttrdtzaqyZHunXfeSdarjfNv3769Yu2aa66pqae8dHR0VKytWrUque3NN9+crHOeQH2GcuT/jaT5gyxf5+6zsn8EHxhmqobf3d+W9HkTegHQRPV85r/DzP5iZl1mdkluHQFoilrD/ytJUyXNktQnaW2lFc1shZl1m1l3uVyutBqAJqsp/O5+0N1PuftpSb+WNCex7np3L7l7qa2trdY+AeSspvCb2aQBDxdJauxPwwDkbihDfc9Juk7SBDPrlbRG0nVmNkuSS+qR9NMG9gigAaqG392XDrL4mQb0EtaUKVOS9Xnz5iXrF198ccXa1KlTa+rpjN7e3mR9x44dyfr7779fsXbrrbcmt12yZEmy3tXVlaxzHkAaZ/gBQRF+ICjCDwRF+IGgCD8QFOEHguLS3S1g2rRpyfrrr7/epE7O3YkTJ5L1Dz/8sGLtoYceSm67cePGZP2qq65K1u+///5kPTqO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8qMuFF16YrE+cOLFiraenp659c2Wo+nDkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOdHXd56661kfeXKlRVrO3fuTG7b2dmZrN92223JOtI48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFXH+c1ssqRnJX1P0mlJ6939MTO7VNImSe2SeiTd4u5HGtcqKjl58mTF2tixY5Pbfvnll8n6gw8+mKw/8cQTNT//3Llzk9uuW7cuWR8/fnyyjrShHPm/kfQLd79K0t9L+pmZXS1plaQ33X2apDezxwCGiarhd/c+d9+R3T8maY+kyyUtkLQhW22DpIWNahJA/s7pM7+ZtUvqkPRnSRPdvU/q/wMh6bK8mwPQOEMOv5mNk7RZ0s/d/eg5bLfCzLrNrLtcLtfSI4AGGFL4zWyM+oP/W3f/Q7b4oJlNyuqTJB0abFt3X+/uJXcvccFFoHVUDb+ZmaRnJO1x918OKG2RtCy7v0zSS/m3B6BRhvKT3k5JP5a008w+yJatlvSIpN+b2XJJ+yQtbkyLI9+xY8eS9a1btybrn3zyScVaX19fcttXXnklWf/ss8+S9fPPPz9ZX7NmTcXaXXfdldyWobzGqhp+d/+TJKtQ/kG+7QBoFs7wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbtzcOrUqWR97dq1yfp9992XrM+YMSNZ37t3b8Va6ue+kjRqVPrvf7Wf3T755JPJekdHR7KO4nDkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOfPwb333pusP/roo3U9/+7du5P1886r/J9x9uzZyW2rXZp7/vz5yTqGL478QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/w56OzsTNb379+frO/bty9ZX7lyZbK+cGHlOVKrXVcfcXHkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgqo7zm9lkSc9K+p6k05LWu/tjZvaApJ9IKmerrnb39ETyI9SCBQvqqgNFGMpJPt9I+oW77zCz8ZK2m9m2rLbO3eu7UgWAQlQNv7v3SerL7h8zsz2SLm90YwAa65w+85tZu6QOSX/OFt1hZn8xsy4zu6TCNivMrNvMusvl8mCrACjAkMNvZuMkbZb0c3c/KulXkqZKmqX+dwaDTkjn7uvdveTupba2thxaBpCHIYXfzMaoP/i/dfc/SJK7H3T3U+5+WtKvJc1pXJsA8lY1/GZmkp6RtMfdfzlg+aQBqy2StCv/9gA0ylC+7e+U9GNJO83sg2zZaklLzWyWJJfUI+mnDekQQEMM5dv+P0myQUohx/SBkYIz/ICgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZuzdvZ2ZlSZ8NWDRB0uGmNXBuWrW3Vu1Lorda5dnb37j7kK6X19Twf2fnZt3uXiqsgYRW7a1V+5LorVZF9cbbfiAowg8EVXT41xe8/5RW7a1V+5LorVaF9FboZ34AxSn6yA+gIIWE38zmm9n/mtnHZraqiB4qMbMeM9tpZh+YWXfBvXSZ2SEz2zVg2aVmts3M9ma3g06TVlBvD5jZ/2Wv3Qdm9k8F9TbZzP7TzPaY2W4z+5dseaGvXaKvQl63pr/tN7PRkj6SdIOkXknvSVrq7h82tZEKzKxHUsndCx8TNrN/lHRc0rPuPjNb9u+SPnf3R7I/nJe4+7+2SG8PSDpe9MzN2YQykwbOLC1poaR/VoGvXaKvW1TA61bEkX+OpI/d/VN3PylpoyQmsB+Eu78t6fOzFi+QtCG7v0H9//M0XYXeWoK797n7juz+MUlnZpYu9LVL9FWIIsJ/uaT9Ax73qrWm/HZJfzSz7Wa2ouhmBjExmzb9zPTplxXcz9mqztzcTGfNLN0yr10tM17nrYjwDzb7TysNOXS6+99J+qGkn2VvbzE0Q5q5uVkGmVm6JdQ643Xeigh/r6TJAx5/X9KBAvoYlLsfyG4PSXpBrTf78MEzk6Rmt4cK7uevWmnm5sFmllYLvHatNON1EeF/T9I0M5tiZmMlLZG0pYA+vsPMLsq+iJGZXSRpnlpv9uEtkpZl95dJeqnAXr6lVWZurjSztAp+7VptxutCTvLJhjL+Q9JoSV3u/m9Nb2IQZva36j/aS/2TmP6uyN7M7DlJ16n/V18HJa2R9KKk30u6QtI+SYvdvelfvFXo7Tr1v3X968zNZz5jN7m3f5D0X5J2SjqdLV6t/s/Xhb12ib6WqoDXjTP8gKA4ww8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/D7bJ7fOxqyetAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_number = 23 # Number between 0 and 10 000 \n",
    "\n",
    "x = eval_data[image_number]\n",
    "y = np.argmax(forward_pass(x.reshape(784, 1), W_0, W_1, W_2, b_0, b_1, b_2)[0])\n",
    "print(\"The predicted number is: \", y)\n",
    "plt.imshow(-x.reshape((28,28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
